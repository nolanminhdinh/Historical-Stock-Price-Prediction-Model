# Historical-Stock-Price-Prediction-Model

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nolanminhdinh/Historical-Stock-Price-Prediction-Model/blob/main/SOTA.ipynb)

## Tá»•ng quan dá»± Ã¡n

Dá»± Ã¡n nÃ y táº­p trung xÃ¢y dá»±ng vÃ  triá»ƒn khai má»™t mÃ´ hÃ¬nh **Deep Learning tiÃªn tiáº¿n (State-of-the-Art)** Ä‘á»ƒ dá»± Ä‘oÃ¡n xu hÆ°á»›ng giÃ¡ cá»• phiáº¿u cá»§a cÃ¡c doanh nghiá»‡p lá»›n táº¡i Viá»‡t Nam (vÃ­ dá»¥ trong dá»± Ã¡n **HPG**, **MBB**).

KhÃ¡c vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p thá»‘ng kÃª truyá»n thá»‘ng, dá»± Ã¡n sá»­ dá»¥ng kiáº¿n trÃºc máº¡ng lai (Hybrid Architecture) phá»©c táº¡p nháº±m tá»‘i Æ°u hÃ³a Ä‘á»™ chÃ­nh xÃ¡c:
* **CNN (Convolutional Neural Networks):** TrÃ­ch xuáº¥t cÃ¡c Ä‘áº·c trÆ°ng ngáº¯n háº¡n vÃ  xu hÆ°á»›ng biáº¿n Ä‘á»™ng tá»« dá»¯ liá»‡u thÃ´.
* **Bi-LSTM (Bidirectional LSTM):** Há»c sá»± phá»¥ thuá»™c dÃ i háº¡n cá»§a chuá»—i thá»i gian theo cáº£ hai chiá»u (quÃ¡ khá»© vÃ  tÆ°Æ¡ng lai).
* **Attention Mechanism (CÆ¡ cháº¿ ChÃº Ã½):** Tá»± Ä‘á»™ng Ä‘Ã¡nh trá»ng sá»‘ cho cÃ¡c má»‘c thá»i gian quan trá»ng, giÃºp mÃ´ hÃ¬nh táº­p trung vÃ o cÃ¡c biáº¿n Ä‘á»™ng giÃ¡ cÃ³ Ã½ nghÄ©a nháº¥t.

--

## ğŸ§  Kiáº¿n trÃºc MÃ´ hÃ¬nh: MÃ´ phá»ng TÆ° duy NhÃ  Ä‘áº§u tÆ° (Model Architecture)

Äiá»ƒm Ä‘á»™c Ä‘Ã¡o cá»§a dá»± Ã¡n lÃ  viá»‡c thiáº¿t káº¿ kiáº¿n trÃºc máº¡ng lai (Hybrid Architecture) nháº±m **mÃ´ phá»ng láº¡i quÃ¡ trÃ¬nh ra quyáº¿t Ä‘á»‹nh cá»§a má»™t nhÃ  Ä‘áº§u tÆ° chuyÃªn nghiá»‡p**. 

Má»—i lá»›p trong mÃ´ hÃ¬nh Ä‘Ã³ng vai trÃ² nhÆ° má»™t bÆ°á»›c trong tÆ° duy phÃ¢n tÃ­ch:

### 1. Quan sÃ¡t & Nháº­n diá»‡n (Feature Extraction - CNN)
> *"NhÃ  Ä‘áº§u tÆ° nhÃ¬n vÃ o biá»ƒu Ä‘á»“ náº¿n Ä‘á»ƒ náº¯m báº¯t cÃ¡c máº«u hÃ¬nh giÃ¡ ngáº¯n háº¡n."*

* **Lá»›p CNN (Convolutional Neural Network):** ÄÃ³ng vai trÃ² nhÆ° "Ä‘Ã´i máº¯t", trÃ­ch xuáº¥t cÃ¡c Ä‘áº·c trÆ°ng quan trá»ng tá»« dá»¯ liá»‡u thÃ´ (giÃ¡ Ä‘Ã³ng cá»­a, khá»‘i lÆ°á»£ng).
* **TÃ¡c dá»¥ng:** Loáº¡i bá» nhiá»…u (noise) cá»§a thá»‹ trÆ°á»ng hÃ ng ngÃ y vÃ  nháº­n diá»‡n cÃ¡c máº«u hÃ¬nh biáº¿n Ä‘á»™ng cá»¥c bá»™ (local patterns) nhÆ° xu hÆ°á»›ng tÄƒng/giáº£m Ä‘á»™t ngá»™t.

### 2. PhÃ¢n tÃ­ch Xu hÆ°á»›ng Chuá»—i (Trend Analysis - Bi-LSTM)
> *"NhÃ  Ä‘áº§u tÆ° xÃ¢u chuá»—i dá»¯ liá»‡u quÃ¡ khá»© vÃ  hiá»‡n táº¡i Ä‘á»ƒ hiá»ƒu bá»‘i cáº£nh thá»‹ trÆ°á»ng."*

* **Lá»›p Bi-LSTM (Bidirectional LSTM):** ÄÃ³ng vai trÃ² nhÆ° "bá»™ nhá»›", há»c sá»± phá»¥ thuá»™c cá»§a chuá»—i thá»i gian theo cáº£ hai chiá»u: tá»« QuÃ¡ khá»© -> Hiá»‡n táº¡i vÃ  tá»« TÆ°Æ¡ng lai (trong ngá»¯ cáº£nh training) -> QuÃ¡ khá»©.
* **TÃ¡c dá»¥ng:** GiÃºp mÃ´ hÃ¬nh khÃ´ng chá»‰ nhÃ¬n tháº¥y giÃ¡ ngÃ y hÃ´m nay mÃ  cÃ²n hiá»ƒu Ä‘Æ°á»£c Ä‘Ã  tÄƒng trÆ°á»Ÿng (momentum) tÃ­ch lÅ©y tá»« chuá»—i ngÃ y trÆ°á»›c Ä‘Ã³.

### 3. Táº­p trung vÃ o Äiá»ƒm Ä‘á»™t biáº¿n (Attention Mechanism)
> *"NhÃ  Ä‘áº§u tÆ° bá» qua nhá»¯ng ngÃ y thá»‹ trÆ°á»ng Ä‘i ngang (sideway) vÃ  dá»“n sá»± chÃº Ã½ vÃ o cÃ¡c phiÃªn cÃ³ biáº¿n Ä‘á»™ng máº¡nh Ä‘á»ƒ ra quyáº¿t Ä‘á»‹nh."*

* **CÆ¡ cháº¿ Attention:** ÄÃ³ng vai trÃ² nhÆ° "trá»±c giÃ¡c", tá»± Ä‘á»™ng gÃ¡n trá»ng sá»‘ cao hÆ¡n cho cÃ¡c má»‘c thá»i gian cÃ³ áº£nh hÆ°á»Ÿng lá»›n Ä‘áº¿n giÃ¡ tÆ°Æ¡ng lai (vÃ­ dá»¥: cÃ¡c phiÃªn cÃ³ khá»‘i lÆ°á»£ng giao dá»‹ch Ä‘á»™t biáº¿n).
* **TÃ¡c dá»¥ng:** GiÃºp mÃ´ hÃ¬nh táº­p trung vÃ o "tÃ­n hiá»‡u" (signals) thay vÃ¬ bá»‹ phÃ¢n tÃ¢m bá»Ÿi cÃ¡c dá»¯ liá»‡u Ã­t quan trá»ng, tá»« Ä‘Ã³ tá»‘i Æ°u hÃ³a Ä‘á»™ chÃ­nh xÃ¡c dá»± bÃ¡o.
---

## Äiá»ƒm ná»•i báº­t (Key Features)

* **Quy trÃ¬nh dá»¯ liá»‡u tá»± Ä‘á»™ng (Automated Pipeline):** Tá»± Ä‘á»™ng thu tháº­p dá»¯ liá»‡u lá»‹ch sá»­ vÃ  realtime thÃ´ng qua thÆ° viá»‡n `vnstock`.
* **Xá»­ lÃ½ dá»¯ liá»‡u nÃ¢ng cao:** Chuáº©n hÃ³a dá»¯ liá»‡u sá»­ dá»¥ng ká»¹ thuáº­t Robust Scaling (dá»±a trÃªn phÃ¢n vá»‹ IQR) thay vÃ¬ MinMax thÃ´ng thÆ°á»ng Ä‘iá»u nÃ y giÃºp loáº¡i bá» áº£nh hÆ°á»Ÿng cá»§a cÃ¡c phiÃªn giao dá»‹ch Ä‘á»™t biáº¿n (Outliers), giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c xu hÆ°á»›ng thá»±c cháº¥t cá»§a thá»‹ trÆ°á»ng vÃ  xá»­ lÃ½ chuá»—i thá»i gian báº±ng ká»¹ thuáº­t Sliding Window.
* **MÃ´ hÃ¬nh SOTA:** Káº¿t há»£p `Conv1D` + `Bi-LSTM` + `Attention Layer` Ä‘á»ƒ giáº£m thiá»ƒu sai sá»‘ dá»± bÃ¡o.
* **ÄÃ¡nh giÃ¡ toÃ n diá»‡n:** Sá»­ dá»¥ng cÃ¡c chá»‰ sá»‘ RMSE, MAE, MAPE vÃ  R2-Score Ä‘á»ƒ kiá»ƒm chá»©ng hiá»‡u quáº£.

---

##  CÃ´ng nghá»‡ & Cáº¥u trÃºc

**Programming language**: Python
**Libraries & Frameworks**: TensorFlow (Keras), Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn, Vnstock.
**Tools & Platforms**: Google Colab, Jupyter Notebook, Git/GitHub.

Cáº¥u trÃºc thÆ° má»¥c dá»± Ã¡n:

```text
â”œâ”€â”€ ğŸ“‚ data/               # Chá»©a dá»¯ liá»‡u thÃ´ vÃ  dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ (HPG, MBB)
â”œâ”€â”€ ğŸ“‚ models/             # Chá»©a file Scaler (.pkl) vÃ  cáº¥u hÃ¬nh Model
â”œâ”€â”€ ğŸ“‚ notebooks/          # MÃ£ nguá»“n chÃ­nh (Jupyter Notebooks)
â”‚   â”œâ”€â”€ Collection_Data.ipynb  # Code thu tháº­p dá»¯ liá»‡u tá»± Ä‘á»™ng
â”‚   â””â”€â”€ SOTA.ipynb             # Code huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
â”œâ”€â”€ ğŸ“‚ images/             # áº¢nh biá»ƒu Ä‘á»“ káº¿t quáº£ (dÃ¹ng cho bÃ¡o cÃ¡o)
â”œâ”€â”€ requirements.txt       # Danh sÃ¡ch cÃ¡c thÆ° viá»‡n cáº§n cÃ i Ä‘áº·t
â””â”€â”€ README.md              # ThÃ´ng tin mÃ´ táº£, tÃ i liá»‡u hÆ°á»›ng dáº«n
